{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt \n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam, rmsprop, sgd\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as Ka\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import array\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contexte \n",
    "\n",
    "Le but de ce notebook est d'élaborer un modèle capable de prédire la variable top_converti ( suite du notebook prepare_data_2 ).\n",
    "\n",
    "Pour cela, nous allons utiliser un réseau de neurones à l'aide de la libraire Keras\n",
    "\n",
    "En terme de performance, le modèle entrainé ici a une précision de 98.2 % sur le jeu de test composé de 9900 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_ori = pd.read_pickle(\"./predictors.pkl\")\n",
    "target_ori = pd.read_pickle(\"./target.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = predictors_ori.copy()\n",
    "target = target_ori.copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COOKIE_ID</th>\n",
       "      <th>actions_0</th>\n",
       "      <th>actions_1</th>\n",
       "      <th>actu_0</th>\n",
       "      <th>actu_1</th>\n",
       "      <th>actualite_0</th>\n",
       "      <th>actualite_1</th>\n",
       "      <th>actualites_0</th>\n",
       "      <th>actualites_1</th>\n",
       "      <th>affaire_0</th>\n",
       "      <th>...</th>\n",
       "      <th>user_0</th>\n",
       "      <th>user_1</th>\n",
       "      <th>video_0</th>\n",
       "      <th>video_1</th>\n",
       "      <th>videos_0</th>\n",
       "      <th>videos_1</th>\n",
       "      <th>vie_0</th>\n",
       "      <th>vie_1</th>\n",
       "      <th>ville_0</th>\n",
       "      <th>ville_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  COOKIE_ID actions_0 actions_1 actu_0 actu_1 actualite_0 actualite_1  \\\n",
       "0         0         1         0      1      0           1           0   \n",
       "1         1         1         0      0      1           1           0   \n",
       "2         2         0         1      0      1           0           1   \n",
       "3         3         1         0      1      0           1           0   \n",
       "4         4         1         0      1      0           1           0   \n",
       "\n",
       "  actualites_0 actualites_1 affaire_0   ...   user_0 user_1 video_0 video_1  \\\n",
       "0            0            1         1   ...        1      0       0       1   \n",
       "1            0            1         1   ...        1      0       0       1   \n",
       "2            0            1         0   ...        1      0       0       1   \n",
       "3            0            1         1   ...        1      0       0       1   \n",
       "4            1            0         1   ...        1      0       1       0   \n",
       "\n",
       "  videos_0 videos_1 vie_0 vie_1 ville_0 ville_1  \n",
       "0        1        0     1     0       1       0  \n",
       "1        1        0     0     1       1       0  \n",
       "2        0        1     0     1       0       1  \n",
       "3        1        0     1     0       0       1  \n",
       "4        1        0     1     0       1       0  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Deux fonctions utiles\n",
    "\n",
    "La première permet de voir l'évolution de la loss et de l'accuracy sur le jeu de test et de validation pendant l'apprentissage. Elle nous permet de diagnostiquer un éventuel sur-apprentissage.\n",
    "\n",
    "La deuxième permet de construire et de compiler un réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLog(history):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "def build_NN(input_dim, output_dim, lr=0.0001):\n",
    "    model  = Sequential()\n",
    "\n",
    "\n",
    "    model.add(Dense(1000,activation='relu',input_shape=(input_dim,)))\n",
    "    model.add(Dense(10,activation='relu',input_shape=(input_dim,)))\n",
    "    #model.add(Dropout(0.70))\n",
    "    \n",
    "    #model.add(Dense(100,activation='relu'))\n",
    "    #model.add(Dropout(0.50))\n",
    "        \n",
    "    model.add(Dense(output_dim,activation='softmax'))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=lr)\n",
    "    #Compile the network\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Jeu de test et d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(predictors, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_df.values\n",
    "X_test = X_test_df.values\n",
    "y_train = y_train_df.values\n",
    "y_test = y_test_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]-1\n",
    "output_dim = y_train.shape[1]-1\n",
    "lr = 0.001\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5746 samples, validate on 2831 samples\n",
      "Epoch 1/10000\n",
      "5746/5746 [==============================] - 1s 210us/step - loss: 0.6404 - acc: 0.7405 - val_loss: 0.5589 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.79477, saving model to weights-improvement-01-0.79.hdf5\n",
      "Epoch 2/10000\n",
      "5746/5746 [==============================] - 1s 193us/step - loss: 0.5199 - acc: 0.7986 - val_loss: 0.5117 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.79477\n",
      "Epoch 3/10000\n",
      "5746/5746 [==============================] - 1s 185us/step - loss: 0.5057 - acc: 0.7986 - val_loss: 0.5106 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.79477\n",
      "Epoch 4/10000\n",
      "5746/5746 [==============================] - 1s 228us/step - loss: 0.5048 - acc: 0.7986 - val_loss: 0.5099 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.79477\n",
      "Epoch 5/10000\n",
      "5746/5746 [==============================] - 1s 196us/step - loss: 0.5040 - acc: 0.7986 - val_loss: 0.5093 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.79477\n",
      "Epoch 6/10000\n",
      "5746/5746 [==============================] - 1s 191us/step - loss: 0.5034 - acc: 0.7986 - val_loss: 0.5087 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.79477\n",
      "Epoch 7/10000\n",
      "5746/5746 [==============================] - 1s 200us/step - loss: 0.5027 - acc: 0.7986 - val_loss: 0.5082 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.79477\n",
      "Epoch 8/10000\n",
      "5746/5746 [==============================] - 1s 194us/step - loss: 0.5022 - acc: 0.7986 - val_loss: 0.5077 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.79477\n",
      "Epoch 9/10000\n",
      "5746/5746 [==============================] - 1s 215us/step - loss: 0.5015 - acc: 0.7986 - val_loss: 0.5072 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.79477\n",
      "Epoch 10/10000\n",
      "5746/5746 [==============================] - 1s 188us/step - loss: 0.5010 - acc: 0.7986 - val_loss: 0.5068 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.79477\n",
      "Epoch 11/10000\n",
      "5746/5746 [==============================] - 1s 198us/step - loss: 0.5005 - acc: 0.7986 - val_loss: 0.5064 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.79477\n",
      "Epoch 12/10000\n",
      "5746/5746 [==============================] - 1s 198us/step - loss: 0.4999 - acc: 0.7986 - val_loss: 0.5058 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.79477\n",
      "Epoch 13/10000\n",
      "5746/5746 [==============================] - 1s 197us/step - loss: 0.4994 - acc: 0.7986 - val_loss: 0.5055 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.79477\n",
      "Epoch 14/10000\n",
      "5746/5746 [==============================] - 1s 227us/step - loss: 0.4988 - acc: 0.7986 - val_loss: 0.5049 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.79477\n",
      "Epoch 15/10000\n",
      "5746/5746 [==============================] - 1s 218us/step - loss: 0.4982 - acc: 0.7986 - val_loss: 0.5044 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.79477\n",
      "Epoch 16/10000\n",
      "5746/5746 [==============================] - 1s 188us/step - loss: 0.4976 - acc: 0.7986 - val_loss: 0.5041 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.79477\n",
      "Epoch 17/10000\n",
      "5746/5746 [==============================] - 1s 194us/step - loss: 0.4970 - acc: 0.7986 - val_loss: 0.5039 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.79477\n",
      "Epoch 18/10000\n",
      "5746/5746 [==============================] - 1s 194us/step - loss: 0.4965 - acc: 0.7986 - val_loss: 0.5031 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.79477\n",
      "Epoch 19/10000\n",
      "5746/5746 [==============================] - 1s 210us/step - loss: 0.4959 - acc: 0.7986 - val_loss: 0.5027 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.79477\n",
      "Epoch 20/10000\n",
      "5746/5746 [==============================] - 1s 209us/step - loss: 0.4955 - acc: 0.7986 - val_loss: 0.5024 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.79477\n",
      "Epoch 21/10000\n",
      "5746/5746 [==============================] - 1s 187us/step - loss: 0.4948 - acc: 0.7986 - val_loss: 0.5019 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.79477\n",
      "Epoch 22/10000\n",
      "5746/5746 [==============================] - 1s 189us/step - loss: 0.4943 - acc: 0.7986 - val_loss: 0.5015 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.79477\n",
      "Epoch 23/10000\n",
      "5746/5746 [==============================] - 1s 217us/step - loss: 0.4937 - acc: 0.7986 - val_loss: 0.5011 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.79477\n",
      "Epoch 24/10000\n",
      "5746/5746 [==============================] - 1s 192us/step - loss: 0.4930 - acc: 0.7986 - val_loss: 0.5011 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.79477\n",
      "Epoch 25/10000\n",
      "5746/5746 [==============================] - 1s 204us/step - loss: 0.4926 - acc: 0.7986 - val_loss: 0.5004 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.79477\n",
      "Epoch 26/10000\n",
      "5746/5746 [==============================] - 1s 206us/step - loss: 0.4920 - acc: 0.7986 - val_loss: 0.5001 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.79477\n",
      "Epoch 27/10000\n",
      "5746/5746 [==============================] - 1s 205us/step - loss: 0.4914 - acc: 0.7986 - val_loss: 0.5004 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.79477\n",
      "Epoch 28/10000\n",
      "5746/5746 [==============================] - 1s 205us/step - loss: 0.4909 - acc: 0.7986 - val_loss: 0.4995 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.79477\n",
      "Epoch 29/10000\n",
      "5746/5746 [==============================] - 1s 206us/step - loss: 0.4903 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.79477\n",
      "Epoch 30/10000\n",
      "5746/5746 [==============================] - 1s 208us/step - loss: 0.4898 - acc: 0.7986 - val_loss: 0.4987 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.79477\n",
      "Epoch 31/10000\n",
      "5746/5746 [==============================] - 1s 214us/step - loss: 0.4891 - acc: 0.7986 - val_loss: 0.4988 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.79477\n",
      "Epoch 32/10000\n",
      "5746/5746 [==============================] - 1s 214us/step - loss: 0.4887 - acc: 0.7986 - val_loss: 0.4979 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.79477\n",
      "Epoch 33/10000\n",
      "5746/5746 [==============================] - 1s 244us/step - loss: 0.4881 - acc: 0.7986 - val_loss: 0.4977 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.79477\n",
      "Epoch 34/10000\n",
      "5746/5746 [==============================] - 1s 208us/step - loss: 0.4874 - acc: 0.7986 - val_loss: 0.4973 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.79477\n",
      "Epoch 35/10000\n",
      "5746/5746 [==============================] - 1s 203us/step - loss: 0.4868 - acc: 0.7986 - val_loss: 0.4971 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.79477\n",
      "Epoch 36/10000\n",
      "5746/5746 [==============================] - 1s 207us/step - loss: 0.4861 - acc: 0.7986 - val_loss: 0.4966 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.79477\n",
      "Epoch 37/10000\n",
      "5746/5746 [==============================] - 1s 201us/step - loss: 0.4856 - acc: 0.7986 - val_loss: 0.4963 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.79477\n",
      "Epoch 38/10000\n",
      "5746/5746 [==============================] - 1s 199us/step - loss: 0.4850 - acc: 0.7986 - val_loss: 0.4959 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.79477\n",
      "Epoch 39/10000\n",
      "5746/5746 [==============================] - 1s 200us/step - loss: 0.4842 - acc: 0.7988 - val_loss: 0.4955 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.79477\n",
      "Epoch 40/10000\n",
      "5746/5746 [==============================] - 1s 197us/step - loss: 0.4834 - acc: 0.7986 - val_loss: 0.4962 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.79477\n",
      "Epoch 41/10000\n",
      "5746/5746 [==============================] - 1s 198us/step - loss: 0.4831 - acc: 0.7988 - val_loss: 0.4950 - val_acc: 0.7941\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.79477\n",
      "Epoch 42/10000\n",
      "5746/5746 [==============================] - 1s 196us/step - loss: 0.4823 - acc: 0.7988 - val_loss: 0.4958 - val_acc: 0.7944\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.79477\n",
      "Epoch 43/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5746/5746 [==============================] - 1s 190us/step - loss: 0.4818 - acc: 0.7990 - val_loss: 0.4952 - val_acc: 0.7941\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.79477\n",
      "Epoch 44/10000\n",
      "5746/5746 [==============================] - 1s 194us/step - loss: 0.4813 - acc: 0.7988 - val_loss: 0.4946 - val_acc: 0.7930\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.79477\n",
      "Epoch 45/10000\n",
      "5746/5746 [==============================] - 1s 193us/step - loss: 0.4805 - acc: 0.7993 - val_loss: 0.4945 - val_acc: 0.7930\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.79477\n",
      "Epoch 46/10000\n",
      "5746/5746 [==============================] - 1s 197us/step - loss: 0.4799 - acc: 0.7999 - val_loss: 0.4944 - val_acc: 0.7937\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.79477\n",
      "Epoch 47/10000\n",
      "5746/5746 [==============================] - 1s 197us/step - loss: 0.4796 - acc: 0.8004 - val_loss: 0.4946 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.79477\n",
      "Epoch 48/10000\n",
      "5746/5746 [==============================] - 1s 195us/step - loss: 0.4791 - acc: 0.8002 - val_loss: 0.4950 - val_acc: 0.7930\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.79477\n",
      "Epoch 49/10000\n",
      "5746/5746 [==============================] - 1s 190us/step - loss: 0.4786 - acc: 0.8004 - val_loss: 0.4944 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.79477\n",
      "Epoch 50/10000\n",
      "5746/5746 [==============================] - 1s 192us/step - loss: 0.4780 - acc: 0.8004 - val_loss: 0.4942 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.79477\n",
      "Epoch 51/10000\n",
      "5746/5746 [==============================] - 1s 193us/step - loss: 0.4775 - acc: 0.8006 - val_loss: 0.4959 - val_acc: 0.7930\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.79477\n",
      "Epoch 52/10000\n",
      "5746/5746 [==============================] - 1s 217us/step - loss: 0.4771 - acc: 0.8013 - val_loss: 0.4944 - val_acc: 0.7930\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.79477\n",
      "Epoch 53/10000\n",
      "5746/5746 [==============================] - 1s 202us/step - loss: 0.4768 - acc: 0.8009 - val_loss: 0.4943 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.79477\n",
      "Epoch 54/10000\n",
      "5746/5746 [==============================] - 1s 196us/step - loss: 0.4761 - acc: 0.8011 - val_loss: 0.4944 - val_acc: 0.7937\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.79477\n",
      "Epoch 55/10000\n",
      "5746/5746 [==============================] - 1s 213us/step - loss: 0.4758 - acc: 0.8013 - val_loss: 0.4943 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.79477\n",
      "Epoch 56/10000\n",
      "5746/5746 [==============================] - 1s 243us/step - loss: 0.4755 - acc: 0.8011 - val_loss: 0.4948 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.79477\n",
      "Epoch 57/10000\n",
      "5746/5746 [==============================] - 1s 210us/step - loss: 0.4752 - acc: 0.8013 - val_loss: 0.4945 - val_acc: 0.7927\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.79477\n",
      "Epoch 58/10000\n",
      "5746/5746 [==============================] - 1s 236us/step - loss: 0.4743 - acc: 0.8011 - val_loss: 0.4955 - val_acc: 0.7927\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.79477\n",
      "Epoch 59/10000\n",
      "5746/5746 [==============================] - 1s 239us/step - loss: 0.4741 - acc: 0.8011 - val_loss: 0.4947 - val_acc: 0.7937\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.79477\n",
      "Epoch 60/10000\n",
      "5746/5746 [==============================] - 1s 230us/step - loss: 0.4741 - acc: 0.8014 - val_loss: 0.4951 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.79477\n",
      "Epoch 61/10000\n",
      "5746/5746 [==============================] - 1s 238us/step - loss: 0.4739 - acc: 0.8016 - val_loss: 0.4950 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.79477\n",
      "Epoch 62/10000\n",
      "5746/5746 [==============================] - 1s 220us/step - loss: 0.4735 - acc: 0.8014 - val_loss: 0.4948 - val_acc: 0.7927\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.79477\n",
      "Epoch 63/10000\n",
      "5746/5746 [==============================] - 1s 206us/step - loss: 0.4732 - acc: 0.8019 - val_loss: 0.4948 - val_acc: 0.7927\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.79477\n",
      "Epoch 64/10000\n",
      "5746/5746 [==============================] - 1s 235us/step - loss: 0.4726 - acc: 0.8018 - val_loss: 0.4957 - val_acc: 0.7937\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.79477\n",
      "Epoch 65/10000\n",
      "5746/5746 [==============================] - 1s 221us/step - loss: 0.4727 - acc: 0.8026 - val_loss: 0.4953 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.79477\n",
      "Epoch 66/10000\n",
      "5746/5746 [==============================] - 1s 245us/step - loss: 0.4723 - acc: 0.8018 - val_loss: 0.4955 - val_acc: 0.7930\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.79477\n",
      "Epoch 67/10000\n",
      "5746/5746 [==============================] - 1s 209us/step - loss: 0.4719 - acc: 0.8026 - val_loss: 0.4957 - val_acc: 0.7927\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.79477\n",
      "Epoch 68/10000\n",
      "5746/5746 [==============================] - 1s 200us/step - loss: 0.4714 - acc: 0.8035 - val_loss: 0.4957 - val_acc: 0.7919\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.79477\n",
      "Epoch 69/10000\n",
      "5746/5746 [==============================] - 1s 210us/step - loss: 0.4713 - acc: 0.8028 - val_loss: 0.4954 - val_acc: 0.7930\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.79477\n",
      "Epoch 70/10000\n",
      "5746/5746 [==============================] - 1s 250us/step - loss: 0.4711 - acc: 0.8033 - val_loss: 0.4957 - val_acc: 0.7916\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.79477\n",
      "Epoch 71/10000\n",
      "5746/5746 [==============================] - 1s 215us/step - loss: 0.4705 - acc: 0.8039 - val_loss: 0.4956 - val_acc: 0.7930\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.79477\n",
      "Epoch 72/10000\n",
      "5746/5746 [==============================] - 1s 195us/step - loss: 0.4704 - acc: 0.8033 - val_loss: 0.4971 - val_acc: 0.7937\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.79477\n",
      "Epoch 73/10000\n",
      "5746/5746 [==============================] - 1s 245us/step - loss: 0.4702 - acc: 0.8032 - val_loss: 0.4964 - val_acc: 0.7912\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.79477\n",
      "Epoch 74/10000\n",
      "5746/5746 [==============================] - 1s 206us/step - loss: 0.4700 - acc: 0.8030 - val_loss: 0.4962 - val_acc: 0.7916\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.79477\n",
      "Epoch 75/10000\n",
      "5746/5746 [==============================] - 2s 280us/step - loss: 0.4697 - acc: 0.8033 - val_loss: 0.4966 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.79477\n",
      "Epoch 76/10000\n",
      "5746/5746 [==============================] - 1s 230us/step - loss: 0.4693 - acc: 0.8037 - val_loss: 0.4962 - val_acc: 0.7927\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.79477\n",
      "Epoch 77/10000\n",
      "5746/5746 [==============================] - 1s 206us/step - loss: 0.4688 - acc: 0.8037 - val_loss: 0.4964 - val_acc: 0.7919\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.79477\n",
      "Epoch 78/10000\n",
      "5746/5746 [==============================] - 1s 196us/step - loss: 0.4690 - acc: 0.8039 - val_loss: 0.4977 - val_acc: 0.7895\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.79477\n",
      "Epoch 79/10000\n",
      "5746/5746 [==============================] - 1s 190us/step - loss: 0.4689 - acc: 0.8028 - val_loss: 0.4966 - val_acc: 0.7930\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.79477\n",
      "Epoch 80/10000\n",
      "5746/5746 [==============================] - 1s 199us/step - loss: 0.4685 - acc: 0.8047 - val_loss: 0.4968 - val_acc: 0.7912\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.79477\n"
     ]
    }
   ],
   "source": [
    "model = build_NN( input_dim, output_dim, lr=lr)\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    " \n",
    "callback = EarlyStopping(patience=10)\n",
    "callbacks_list = [checkpoint,callback]\n",
    "\n",
    "history = model.fit(X_train[:,1:], y_train[:,1:], batch_size=16, epochs=epochs, validation_data=(X_test[:,1:], y_test[:,1:]), shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1000)              201000    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                10010     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 211,032\n",
      "Trainable params: 211,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotLog(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Performances du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COOKIE_ID</th>\n",
       "      <th>actions_0</th>\n",
       "      <th>actions_1</th>\n",
       "      <th>actu_0</th>\n",
       "      <th>actu_1</th>\n",
       "      <th>actualite_0</th>\n",
       "      <th>actualite_1</th>\n",
       "      <th>actualites_0</th>\n",
       "      <th>actualites_1</th>\n",
       "      <th>affaire_0</th>\n",
       "      <th>...</th>\n",
       "      <th>user_0</th>\n",
       "      <th>user_1</th>\n",
       "      <th>video_0</th>\n",
       "      <th>video_1</th>\n",
       "      <th>videos_0</th>\n",
       "      <th>videos_1</th>\n",
       "      <th>vie_0</th>\n",
       "      <th>vie_1</th>\n",
       "      <th>ville_0</th>\n",
       "      <th>ville_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>1176</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>2124</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3785</th>\n",
       "      <td>3785</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>1864</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     COOKIE_ID actions_0 actions_1 actu_0 actu_1 actualite_0 actualite_1  \\\n",
       "1176      1176         1         0      0      1           0           1   \n",
       "2124      2124         1         0      1      0           1           0   \n",
       "3785      3785         1         0      1      0           1           0   \n",
       "1864      1864         1         0      0      1           0           1   \n",
       "33          33         1         0      1      0           1           0   \n",
       "\n",
       "     actualites_0 actualites_1 affaire_0   ...   user_0 user_1 video_0  \\\n",
       "1176            1            0         0   ...        0      1       0   \n",
       "2124            1            0         1   ...        1      0       0   \n",
       "3785            0            1         1   ...        1      0       1   \n",
       "1864            0            1         0   ...        1      0       0   \n",
       "33              1            0         1   ...        1      0       1   \n",
       "\n",
       "     video_1 videos_0 videos_1 vie_0 vie_1 ville_0 ville_1  \n",
       "1176       1        0        1     0     1       0       1  \n",
       "2124       1        1        0     1     0       1       0  \n",
       "3785       0        1        0     1     0       1       0  \n",
       "1864       1        0        1     1     0       1       0  \n",
       "33         0        1        0     1     0       1       0  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and float64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3bb3804be7eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'COOKIE_ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     59\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# to avoid incompat dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    984\u001b[0m             elif (not is_numeric_dtype(lk)\n\u001b[1;32m    985\u001b[0m                     and (is_numeric_dtype(rk) and not is_bool_dtype(rk))):\n\u001b[0;32m--> 986\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on object and float64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "test_df = pd.merge(X_test_df, y_test_df, on='COOKIE_ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_fcom_sha256</th>\n",
       "      <th>year_birthdate</th>\n",
       "      <th>fld_account_fcom_create_date</th>\n",
       "      <th>date_souscription_essai</th>\n",
       "      <th>sum_fld_evt_discount_price_ht_on_en_essai=False_&amp;_fld_evt_type_fk=13</th>\n",
       "      <th>sum_fld_evt_discount_price_ht_on_en_essai=True_&amp;_fld_evt_type_fk=13</th>\n",
       "      <th>sum_fld_evt_discount_price_ht_on_en_essai=False_&amp;_fld_evt_type_fk=1</th>\n",
       "      <th>sum_fld_evt_discount_price_ht_on_en_essai=False_&amp;_fld_evt_type_fk=20</th>\n",
       "      <th>sum_fld_evt_discount_price_ht_on_en_essai=False_&amp;_fld_evt_type_fk=3</th>\n",
       "      <th>sum_fld_evt_discount_price_ht_on_en_essai=False_&amp;_fld_evt_type_fk=6</th>\n",
       "      <th>...</th>\n",
       "      <th>sum_fld_evt_discount_price_ht_on_week_2=True_&amp;_fld_evt_type_fk=6</th>\n",
       "      <th>sum_fld_evt_discount_price_ht_on_week_2=True_&amp;_fld_evt_type_fk=4</th>\n",
       "      <th>sum_fld_evt_discount_price_ht_on_week_2=True_&amp;_fld_evt_type_fk=3</th>\n",
       "      <th>fld_acc_gender_id_fk_0</th>\n",
       "      <th>fld_acc_gender_id_fk_1</th>\n",
       "      <th>fld_acc_gender_id_fk_2</th>\n",
       "      <th>fld_email_optin_fk_0</th>\n",
       "      <th>fld_email_optin_fk_1</th>\n",
       "      <th>top_converti_0</th>\n",
       "      <th>top_converti_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5f00b47622b237202683b7273e14d1b02442fb79ebfd89...</td>\n",
       "      <td>0.840336</td>\n",
       "      <td>0.889736</td>\n",
       "      <td>0.0604396</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00143571</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e000d4f709a769ae4ecabb817e21a4d440cf3288a2d284...</td>\n",
       "      <td>0.798319</td>\n",
       "      <td>0.984057</td>\n",
       "      <td>0.700435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0773162</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>279f9ffb6b3a3c8f78d8034b646203ee11781b94100fb2...</td>\n",
       "      <td>0.815126</td>\n",
       "      <td>0.987099</td>\n",
       "      <td>0.75538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00329564</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ad3af8821f254346aac372ac2a85bf91d42e9315048af2...</td>\n",
       "      <td>0.638655</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.846039</td>\n",
       "      <td>0.0134428</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00973932</td>\n",
       "      <td>0.0621259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917045bd6e2166846befc467584124db5d8edb3793d39f...</td>\n",
       "      <td>0.831933</td>\n",
       "      <td>0.950594</td>\n",
       "      <td>0.0631868</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 449 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id_fcom_sha256 year_birthdate  \\\n",
       "0  5f00b47622b237202683b7273e14d1b02442fb79ebfd89...       0.840336   \n",
       "1  e000d4f709a769ae4ecabb817e21a4d440cf3288a2d284...       0.798319   \n",
       "2  279f9ffb6b3a3c8f78d8034b646203ee11781b94100fb2...       0.815126   \n",
       "3  ad3af8821f254346aac372ac2a85bf91d42e9315048af2...       0.638655   \n",
       "4  917045bd6e2166846befc467584124db5d8edb3793d39f...       0.831933   \n",
       "\n",
       "  fld_account_fcom_create_date date_souscription_essai  \\\n",
       "0                     0.889736               0.0604396   \n",
       "1                     0.984057                0.700435   \n",
       "2                     0.987099                 0.75538   \n",
       "3                     0.793103                0.846039   \n",
       "4                     0.950594               0.0631868   \n",
       "\n",
       "  sum_fld_evt_discount_price_ht_on_en_essai=False_&_fld_evt_type_fk=13  \\\n",
       "0                                                  0                     \n",
       "1                                                  0                     \n",
       "2                                                  0                     \n",
       "3                                          0.0134428                     \n",
       "4                                                  0                     \n",
       "\n",
       "  sum_fld_evt_discount_price_ht_on_en_essai=True_&_fld_evt_type_fk=13  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "3                                                  0                    \n",
       "4                                                  0                    \n",
       "\n",
       "  sum_fld_evt_discount_price_ht_on_en_essai=False_&_fld_evt_type_fk=1  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                         0.00329564                    \n",
       "3                                         0.00973932                    \n",
       "4                                                  0                    \n",
       "\n",
       "  sum_fld_evt_discount_price_ht_on_en_essai=False_&_fld_evt_type_fk=20  \\\n",
       "0                                                  0                     \n",
       "1                                                  0                     \n",
       "2                                                  0                     \n",
       "3                                          0.0621259                     \n",
       "4                                                  0                     \n",
       "\n",
       "  sum_fld_evt_discount_price_ht_on_en_essai=False_&_fld_evt_type_fk=3  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "3                                                  0                    \n",
       "4                                                  0                    \n",
       "\n",
       "  sum_fld_evt_discount_price_ht_on_en_essai=False_&_fld_evt_type_fk=6  \\\n",
       "0                                         0.00143571                    \n",
       "1                                          0.0773162                    \n",
       "2                                                  0                    \n",
       "3                                                  0                    \n",
       "4                                                  0                    \n",
       "\n",
       "       ...        \\\n",
       "0      ...         \n",
       "1      ...         \n",
       "2      ...         \n",
       "3      ...         \n",
       "4      ...         \n",
       "\n",
       "  sum_fld_evt_discount_price_ht_on_week_2=True_&_fld_evt_type_fk=6  \\\n",
       "0                                                  0                 \n",
       "1                                                  0                 \n",
       "2                                                  0                 \n",
       "3                                                  0                 \n",
       "4                                                  0                 \n",
       "\n",
       "  sum_fld_evt_discount_price_ht_on_week_2=True_&_fld_evt_type_fk=4  \\\n",
       "0                                                  0                 \n",
       "1                                                  0                 \n",
       "2                                                  0                 \n",
       "3                                                  0                 \n",
       "4                                                  0                 \n",
       "\n",
       "  sum_fld_evt_discount_price_ht_on_week_2=True_&_fld_evt_type_fk=3  \\\n",
       "0                                                  0                 \n",
       "1                                                  0                 \n",
       "2                                                  0                 \n",
       "3                                                  0                 \n",
       "4                                                  0                 \n",
       "\n",
       "  fld_acc_gender_id_fk_0 fld_acc_gender_id_fk_1 fld_acc_gender_id_fk_2  \\\n",
       "0                      0                      0                      1   \n",
       "1                      0                      0                      1   \n",
       "2                      1                      0                      0   \n",
       "3                      0                      0                      1   \n",
       "4                      0                      1                      0   \n",
       "\n",
       "  fld_email_optin_fk_0 fld_email_optin_fk_1 top_converti_0 top_converti_1  \n",
       "0                    1                    0              1              0  \n",
       "1                    0                    1              1              0  \n",
       "2                    0                    1              1              0  \n",
       "3                    1                    0              1              0  \n",
       "4                    0                    1              1              0  \n",
       "\n",
       "[5 rows x 449 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_df.drop(['id_fcom_sha256','top_converti_0','top_converti_1'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tableau qui va contenir les valeurs réelles et les prédictions\n",
    "gt_and_pred = np.empty(shape=(2,0)) \n",
    "gt_and_pred = np.column_stack((gt_and_pred, np.array([np.argmax(test_df[['top_converti_0','top_converti_1']].values, axis=1), np.argmax(predictions, axis=1)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_and_pred = pd.DataFrame(gt_and_pred).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = cohen_kappa_score(gt_and_pred[0], gt_and_pred[1], labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.857239693689082"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(gt_and_pred[0], gt_and_pred[1], labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2513.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.top_converti_1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7008,  379],\n",
       "       [ 171, 2342]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.928702682837194"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taux_faux_positif = conf_mat[0,1] / (conf_mat[0,1]+conf_mat[1,1]) * 100\n",
    "taux_faux_positif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (conf_mat[0,0]+conf_mat[1,1])/(conf_mat.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 826)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_ori.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
